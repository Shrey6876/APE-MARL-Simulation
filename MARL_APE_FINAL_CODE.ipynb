{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dcr37B4OK-n",
        "outputId": "c5dc2e54-8476-491c-9814-98a79d8e5764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ALGORITHMIC PREDATORY EQUILIBRIUM (APE) SIMULATION\n",
            "Publication-Ready Code\n",
            "================================================================================\n",
            "\n",
            "Configuration:\n",
            "  Episodes: 100\n",
            "  Steps/Episode: 250\n",
            "  Loss Aversion (λ): 2.25\n",
            "  Predators: 5\n",
            "  Prey: 95\n",
            "\n",
            "================================================================================\n",
            "Running Scenario A\n",
            "================================================================================\n",
            "Episode  10 | Predator Profit: $    0.00 | Volatility:  0.32%\n",
            "Episode  20 | Predator Profit: $    0.00 | Volatility:  0.34%\n",
            "Episode  30 | Predator Profit: $    0.00 | Volatility:  0.42%\n",
            "Episode  40 | Predator Profit: $    0.00 | Volatility:  0.40%\n",
            "Episode  50 | Predator Profit: $    0.00 | Volatility:  0.50%\n",
            "Episode  60 | Predator Profit: $    0.00 | Volatility:  0.39%\n",
            "Episode  70 | Predator Profit: $    0.00 | Volatility:  0.38%\n",
            "Episode  80 | Predator Profit: $    0.00 | Volatility:  0.45%\n",
            "Episode  90 | Predator Profit: $    0.00 | Volatility:  0.38%\n",
            "Episode 100 | Predator Profit: $    0.00 | Volatility:  0.54%\n",
            "\n",
            "================================================================================\n",
            "Running Scenario B\n",
            "================================================================================\n",
            "Episode  10 | Predator Profit: $ -840.09 | Volatility:  0.33%\n",
            "Episode  20 | Predator Profit: $ -329.85 | Volatility:  0.29%\n",
            "Episode  30 | Predator Profit: $ -496.70 | Volatility:  0.36%\n",
            "Episode  40 | Predator Profit: $ -641.93 | Volatility:  0.33%\n",
            "Episode  50 | Predator Profit: $ -699.99 | Volatility:  0.38%\n",
            "Episode  60 | Predator Profit: $ -756.99 | Volatility:  0.30%\n",
            "Episode  70 | Predator Profit: $ -768.78 | Volatility:  0.39%\n",
            "Episode  80 | Predator Profit: $ -786.45 | Volatility:  0.43%\n",
            "Episode  90 | Predator Profit: $ -811.64 | Volatility:  0.47%\n",
            "Episode 100 | Predator Profit: $ -826.96 | Volatility:  0.39%\n",
            "\n",
            "================================================================================\n",
            "Running Scenario C\n",
            "================================================================================\n",
            "Episode  10 | Predator Profit: $-3533.05 | Volatility:  0.40%\n",
            "Episode  20 | Predator Profit: $-2917.49 | Volatility:  0.47%\n",
            "Episode  30 | Predator Profit: $-3304.00 | Volatility:  0.46%\n",
            "Episode  40 | Predator Profit: $-3664.47 | Volatility:  0.38%\n",
            "Episode  50 | Predator Profit: $-3511.15 | Volatility:  0.44%\n",
            "Episode  60 | Predator Profit: $-3292.17 | Volatility:  0.40%\n",
            "Episode  70 | Predator Profit: $-3520.81 | Volatility:  0.37%\n",
            "Episode  80 | Predator Profit: $-3477.48 | Volatility:  0.36%\n",
            "Episode  90 | Predator Profit: $-3827.59 | Volatility:  0.44%\n",
            "Episode 100 | Predator Profit: $-3353.66 | Volatility:  0.42%\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "                       Scenario A (Rational)  Scenario B (Predatory)  Scenario C (Regulated)\n",
            "Predator Daily Profit           0.000000e+00           -6.959372e+02           -3.440187e+03\n",
            "Predator Total Profit           0.000000e+00           -6.959372e+04           -3.440187e+05\n",
            "Prey Daily Loss                 3.127877e+04            3.489831e+04            3.472181e+04\n",
            "Prey Total Loss                 3.127877e+06            3.489831e+06            3.472181e+06\n",
            "Mean Volatility                 4.104999e-03            3.680138e-03            4.135371e-03\n",
            "Total Cascades                  2.499500e+04            2.492200e+04            2.486100e+04\n",
            "\n",
            "================================================================================\n",
            "PROPOSITION VALIDATION\n",
            "================================================================================\n",
            "\n",
            "Proposition 1 (Volatility Induction):\n",
            "  ✓ Volatility Increase: -10.3%\n",
            "  ✓ Alpha Increase: -inf%\n",
            "  ✓ Validated: False\n",
            "\n",
            "Proposition 2 (Information Cascades):\n",
            "  ✓ Cascade Increase: -0.3%\n",
            "  ✓ Validated: False\n",
            "\n",
            "Regulatory Gap:\n",
            "  ✓ Profit Reduction (Enforcement): -394.3%\n",
            "  ✓ Cascade Reduction: 0.2%\n",
            "  ✓ Residual Alpha (Daily): $-3440.19\n",
            "  ✓ Insufficient Enforcement: False\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1239012011.py:841: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  alpha_increase = (summary_b['mean_predator_daily_profit'] - summary_a['mean_predator_daily_profit']) / summary_a['mean_predator_daily_profit']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "╔════════════════════════════════════════════════════════════════════════════════╗\n",
        "║                                                                                ║\n",
        "║               ALGORITHMIC PREDATORY EQUILIBRIUM (APE)                          ║\n",
        "║            Simulation Code Repository - Complete Implementation                ║\n",
        "║                                                                                ║\n",
        "║  Title: Algorithmic Predatory Equilibrium: Decentralized Markets Under         ║\n",
        "║         Regime Shift from Speed to Cognition                                   ║\n",
        "║                                                                                ║\n",
        "║  Author: [Your Name]                                                           ║\n",
        "║  Date: January 2026                                                            ║\n",
        "║  Status: Publication-Ready                                                     ║\n",
        "║                                                                                ║\n",
        "║  This module contains all agent-based simulation code used to validate         ║\n",
        "║  Propositions 1 and 2, and test regulatory effectiveness (Scenario A, B, C).   ║\n",
        "║                                                                                ║\n",
        "╚════════════════════════════════════════════════════════════════════════════════╝\n",
        "\n",
        "SIMULATION STRUCTURE:\n",
        "====================\n",
        "\n",
        "1. CONFIG & PARAMETERS\n",
        "   - Behavioral calibration (λ = 2.25)\n",
        "   - Market parameters (reserves, prices, gas costs)\n",
        "   - Agent populations (5 predators, 95 prey)\n",
        "   - Episode/step configuration (100 episodes × 250 steps)\n",
        "\n",
        "2. CORE CLASSES\n",
        "   - BaseAgent (abstract agent class)\n",
        "   - PredatorAgent (MARL-based predator with policy gradient)\n",
        "   - PreyAgent (behavioral trader with loss aversion)\n",
        "   - Market (AMM microstructure)\n",
        "   - Simulator (orchestrates multi-scenario runs)\n",
        "\n",
        "3. UTILITY FUNCTIONS\n",
        "   - Prospect theory calculations (utility, panic function)\n",
        "   - Data logging and aggregation\n",
        "   - Statistical validation\n",
        "\n",
        "4. EXECUTION\n",
        "   - Run three scenarios (A: Rational, B: Predatory, C: Regulated)\n",
        "   - Generate results table and figure\n",
        "\n",
        "════════════════════════════════════════════════════════════════════════════════\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from enum import Enum\n",
        "from scipy.special import expit as sigmoid  # logistic sigmoid\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 1: CONFIGURATION & CALIBRATION PARAMETERS\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "@dataclass\n",
        "class SimulationConfig:\n",
        "    \"\"\"\n",
        "    Master configuration for all simulation scenarios.\n",
        "\n",
        "    Attributes match empirical calibrations from:\n",
        "    - Kaustia & Knüpfer (2014): Loss aversion λ = 2.25\n",
        "    - Lussange et al. (2024): MARL on crypto markets\n",
        "    - Flashbots (2024-2025): MEV empirical data\n",
        "    \"\"\"\n",
        "\n",
        "    # Market Structure\n",
        "    initial_reserves: float = 1000.0          # AMM liquidity (normalized)\n",
        "    initial_price: float = 100.0              # Initial token price\n",
        "    initial_balance_predator: float = 500.0   # Predator capital\n",
        "    initial_balance_prey: float = 200.0       # Prey capital\n",
        "\n",
        "    # Behavioral Parameters\n",
        "    loss_aversion_lambda: float = 2.25        # Prospect theory (meta-analyzed)\n",
        "    panic_multiplier: float = 3.0             # Extreme loss reaction\n",
        "    cascade_threshold: float = 0.30           # >30% panic triggers cascade\n",
        "\n",
        "    # Agent Population\n",
        "    n_predators: int = 5                      # MARL agents\n",
        "    n_prey: int = 95                          # Behavioral traders\n",
        "    n_liquidity_providers: int = 0            # Passive LPs (if needed)\n",
        "\n",
        "    # Episode & Step Configuration\n",
        "    n_episodes: int = 100                     # 100 trading days\n",
        "    steps_per_episode: int = 250              # 250 steps = 4 hours/day\n",
        "\n",
        "    # Cost Parameters\n",
        "    gas_cost_per_trade: float = 0.50          # Transaction cost\n",
        "    detection_probability: float = 0.02       # 2% enforcement detection\n",
        "\n",
        "    # Regulatory Parameters (Scenario C)\n",
        "    cancellation_threshold: float = 0.90      # 90% cancellation = violation\n",
        "    fine_magnitude: float = 100.0             # $100 per violation\n",
        "\n",
        "    # Random Seed\n",
        "    random_seed: int = 42\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EpisodeMetrics:\n",
        "    \"\"\"Container for episode-level statistics.\"\"\"\n",
        "\n",
        "    episode_number: int\n",
        "    predator_profit: float = 0.0\n",
        "    predator_volume: float = 0.0\n",
        "    market_volatility: float = 0.0\n",
        "    prey_loss: float = 0.0\n",
        "    prey_volume: float = 0.0\n",
        "    cascade_events: int = 0\n",
        "    panic_selling_count: int = 0\n",
        "    violations_detected: int = 0\n",
        "    regulation_fines: float = 0.0\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 2: BEHAVIORAL FINANCE UTILITY FUNCTIONS\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class ProspectTheory:\n",
        "    \"\"\"\n",
        "    Prospect theory implementation for behavioral agents.\n",
        "\n",
        "    Reference: Kahneman & Tversky (1979); Tversky & Kahneman (1992)\n",
        "\n",
        "    Utility function:\n",
        "        U(w) = w^α                if w ≥ 0\n",
        "        U(w) = -λ(-w)^β           if w < 0\n",
        "\n",
        "    Empirically calibrated: α ≈ β ≈ 0.88; λ ∈ [1.8, 2.1]\n",
        "    \"\"\"\n",
        "\n",
        "    ALPHA = 0.88        # Gain exponent\n",
        "    BETA = 0.88         # Loss exponent\n",
        "    REFERENCE_POINT = 0 # Neutral wealth level\n",
        "\n",
        "    @staticmethod\n",
        "    def utility(wealth: float, lambda_param: float = 2.25) -> float:\n",
        "        \"\"\"\n",
        "        Compute prospect theory utility.\n",
        "\n",
        "        Args:\n",
        "            wealth: Current wealth level\n",
        "            lambda_param: Loss aversion coefficient\n",
        "\n",
        "        Returns:\n",
        "            Utility value\n",
        "        \"\"\"\n",
        "        if wealth >= ProspectTheory.REFERENCE_POINT:\n",
        "            return wealth ** ProspectTheory.ALPHA\n",
        "        else:\n",
        "            loss_magnitude = abs(wealth - ProspectTheory.REFERENCE_POINT)\n",
        "            return -lambda_param * (loss_magnitude ** ProspectTheory.BETA)\n",
        "\n",
        "    @staticmethod\n",
        "    def panic_threshold(\n",
        "        price_shock: float,\n",
        "        market_volatility: float,\n",
        "        lambda_param: float = 2.25\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Compute probability of panic selling given shock.\n",
        "\n",
        "        Panic function: P(sell | shock) = sigmoid(λ * normalized_shock)\n",
        "\n",
        "        Where normalized_shock = (P_t-1 - P_t) / σ_t\n",
        "\n",
        "        Args:\n",
        "            price_shock: Absolute price change (P_t-1 - P_t)\n",
        "            market_volatility: Current σ_t (volatility)\n",
        "            lambda_param: Loss aversion (amplification factor)\n",
        "\n",
        "        Returns:\n",
        "            Probability ∈ [0, 1]\n",
        "        \"\"\"\n",
        "        if market_volatility < 1e-6:  # Avoid division by zero\n",
        "            market_volatility = 1e-6\n",
        "\n",
        "        normalized_shock = price_shock / market_volatility\n",
        "        panic_probability = sigmoid(lambda_param * normalized_shock)\n",
        "\n",
        "        return panic_probability\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 3: AGENT CLASSES\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class BaseAgent:\n",
        "    \"\"\"\n",
        "    Abstract base class for all agents.\n",
        "\n",
        "    Attributes:\n",
        "        agent_id: Unique identifier\n",
        "        balance: Current capital/token holdings\n",
        "        wealth_history: Time series of wealth\n",
        "        is_predator: Boolean flag for agent type\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id: int, initial_balance: float, is_predator: bool):\n",
        "        self.agent_id = agent_id\n",
        "        self.balance = initial_balance\n",
        "        self.wealth_history = [initial_balance]\n",
        "        self.is_predator = is_predator\n",
        "        self.trades_executed = 0\n",
        "        self.total_volume = 0.0\n",
        "\n",
        "    def get_current_wealth(self) -> float:\n",
        "        \"\"\"Return current balance.\"\"\"\n",
        "        return self.balance\n",
        "\n",
        "    def add_to_wealth_history(self, new_balance: float):\n",
        "        \"\"\"Append to wealth history.\"\"\"\n",
        "        self.balance = new_balance\n",
        "        self.wealth_history.append(new_balance)\n",
        "\n",
        "    def execute_trade(self, amount: float, direction: str):\n",
        "        \"\"\"\n",
        "        Record a trade execution.\n",
        "\n",
        "        Args:\n",
        "            amount: Trade size (absolute)\n",
        "            direction: 'buy' or 'sell'\n",
        "        \"\"\"\n",
        "        self.trades_executed += 1\n",
        "        self.total_volume += abs(amount)\n",
        "\n",
        "\n",
        "class PredatorAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    MARL-based predator agent that learns volatility induction.\n",
        "\n",
        "    Uses Policy Gradient optimization (simplified REINFORCE).\n",
        "    State: (price, order book, mempool visibility)\n",
        "    Action: Market order size ∈ [-max_order, +max_order]\n",
        "    Reward: Profit from exploitation\n",
        "\n",
        "    Key insight: Without behavioral prey, predator profit is minimal.\n",
        "                 With behavioral prey (λ=2.25), predator discovers\n",
        "                 volatility-inducing strategies as optimal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        agent_id: int,\n",
        "        initial_balance: float,\n",
        "        config: SimulationConfig\n",
        "    ):\n",
        "        super().__init__(agent_id, initial_balance, is_predator=True)\n",
        "        self.config = config\n",
        "\n",
        "        # Policy parameters (simplified MARL)\n",
        "        self.learning_rate = 0.01\n",
        "        self.policy_weights = np.array([0.1, 0.2, 0.3])  # [size, timing, direction]\n",
        "\n",
        "        # Reward history for policy gradient\n",
        "        self.episode_rewards = []\n",
        "        self.episode_actions = []\n",
        "\n",
        "    def decide_action(\n",
        "        self,\n",
        "        current_price: float,\n",
        "        order_book_imbalance: float,\n",
        "        prey_panic_level: float,\n",
        "        market_volatility: float\n",
        "    ) -> Tuple[float, str]:\n",
        "        \"\"\"\n",
        "        Compute action via learned policy.\n",
        "\n",
        "        Policy discovery: MARL learns that inducing volatility\n",
        "        triggers panic selling in behavioral prey (λ=2.25).\n",
        "\n",
        "        Action = (order_size, direction)\n",
        "\n",
        "        Args:\n",
        "            current_price: Current spot price\n",
        "            order_book_imbalance: OB_buy - OB_sell (signed)\n",
        "            prey_panic_level: Fraction of prey in panic state\n",
        "            market_volatility: Current σ_t\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (order_size, direction)\n",
        "        \"\"\"\n",
        "        # Policy: exploit panic via market impact\n",
        "        # If prey_panic_level high AND volatility rising, place large market order\n",
        "\n",
        "        state = np.array([\n",
        "            order_book_imbalance,\n",
        "            prey_panic_level,\n",
        "            market_volatility\n",
        "        ])\n",
        "\n",
        "        # Simplified policy (linear): π(a|s) ∝ weights · state\n",
        "        action_signal = np.dot(self.policy_weights, state)\n",
        "\n",
        "        # Map to order size (sigmoid bounded)\n",
        "        max_order = 10.0\n",
        "        order_size = max_order * sigmoid(action_signal)\n",
        "\n",
        "        # Direction: exploit if panic high, otherwise accumulate\n",
        "        direction = 'sell' if prey_panic_level > 0.2 else 'buy'\n",
        "\n",
        "        return order_size, direction\n",
        "\n",
        "    def update_policy(self, episode_return: float):\n",
        "        \"\"\"\n",
        "        Simple policy gradient update (REINFORCE).\n",
        "\n",
        "        In production: Would use PPO, TRPO, A3C.\n",
        "        For simulation: Simplified update proportional to returns.\n",
        "        \"\"\"\n",
        "        if episode_return > 0:\n",
        "            # Positive return: increase aggressiveness\n",
        "            self.policy_weights *= (1.0 + self.learning_rate * 0.1)\n",
        "            self.policy_weights = np.clip(self.policy_weights, 0.01, 1.0)\n",
        "\n",
        "\n",
        "class PreyAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Behavioral trader with loss aversion (λ = 2.25).\n",
        "\n",
        "    Uses prospect theory for decision-making.\n",
        "    Exhibits panic selling when losses exceed pain threshold.\n",
        "\n",
        "    Key mechanism: Sigmoid coupling creates threshold effect.\n",
        "    Small shocks → minimal selling. Large shocks → massive panic.\n",
        "    MARL learns to induce large shocks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        agent_id: int,\n",
        "        initial_balance: float,\n",
        "        config: SimulationConfig\n",
        "    ):\n",
        "        super().__init__(agent_id, initial_balance, is_predator=False)\n",
        "        self.config = config\n",
        "        self.reference_price = initial_balance / 100  # Reference for loss calculation\n",
        "        self.is_panicking = False\n",
        "        self.panic_threshold_triggered = False\n",
        "\n",
        "    def decide_action(\n",
        "        self,\n",
        "        current_price: float,\n",
        "        price_change: float,\n",
        "        market_volatility: float,\n",
        "        trading_probability: float = 0.15\n",
        "    ) -> Tuple[bool, float, str]:\n",
        "        \"\"\"\n",
        "        Behavioral decision via prospect theory.\n",
        "\n",
        "        Decision tree:\n",
        "        1. Base trading probability: 15% of prey trade per step\n",
        "        2. If loss: amplify by sigmoid(λ * normalized_shock)\n",
        "        3. If cascade: panic multiplier 3× (herd behavior)\n",
        "\n",
        "        Args:\n",
        "            current_price: Current token price\n",
        "            price_change: P_t-1 - P_t (negative = loss)\n",
        "            market_volatility: Current σ_t\n",
        "            trading_probability: Base trading frequency\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (will_trade, order_size, direction)\n",
        "        \"\"\"\n",
        "        # Base trading decision\n",
        "        will_trade = np.random.random() < trading_probability\n",
        "\n",
        "        if not will_trade:\n",
        "            return False, 0.0, 'hold'\n",
        "\n",
        "        # Loss aversion amplification\n",
        "        if price_change > 0:  # Loss occurred (price fell)\n",
        "            panic_prob = ProspectTheory.panic_threshold(\n",
        "                price_shock=price_change,\n",
        "                market_volatility=market_volatility,\n",
        "                lambda_param=self.config.loss_aversion_lambda\n",
        "            )\n",
        "\n",
        "            # Threshold effect: if panic probable, sell with amplified size\n",
        "            if np.random.random() < panic_prob:\n",
        "                self.is_panicking = True\n",
        "                order_size = 5.0 * self.config.panic_multiplier  # Amplified\n",
        "                direction = 'sell'\n",
        "            else:\n",
        "                self.is_panicking = False\n",
        "                order_size = 2.0  # Normal trade size\n",
        "                direction = 'buy'  # Default to buy after loss (averaging down)\n",
        "        else:\n",
        "            # Gain: conservative trading\n",
        "            self.is_panicking = False\n",
        "            order_size = 1.5\n",
        "            direction = 'buy'\n",
        "\n",
        "        return True, order_size, direction\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 4: MARKET MODEL (AMM MICROSTRUCTURE)\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class Market:\n",
        "    \"\"\"\n",
        "    Automated Market Maker (Uniswap V2 style).\n",
        "\n",
        "    Constant product formula: x * y = k\n",
        "\n",
        "    Predators see full mempool (information advantage).\n",
        "    Prey see only confirmed trades.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: SimulationConfig):\n",
        "        self.config = config\n",
        "        self.reserve_token = config.initial_reserves\n",
        "        self.reserve_stable = config.initial_reserves * config.initial_price\n",
        "        self.k = self.reserve_token * self.reserve_stable  # Constant product\n",
        "\n",
        "        # Price history\n",
        "        self.price_history = [config.initial_price]\n",
        "        self.volatility_history = [0.0]\n",
        "\n",
        "        # Order book simulation\n",
        "        self.pending_orders = []  # Mempool\n",
        "        self.executed_trades = []\n",
        "\n",
        "    def get_current_price(self) -> float:\n",
        "        \"\"\"Compute current spot price from reserves.\"\"\"\n",
        "        return self.reserve_stable / self.reserve_token\n",
        "\n",
        "    def execute_trade(\n",
        "        self,\n",
        "        order_size: float,\n",
        "        direction: str,\n",
        "        agent_id: int\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Execute market order via AMM.\n",
        "\n",
        "        Constant product: (x + dx) * (y - dy) = x * y\n",
        "        Price impact: larger orders face worse prices.\n",
        "\n",
        "        Args:\n",
        "            order_size: Token quantity\n",
        "            direction: 'buy' or 'sell'\n",
        "            agent_id: Executing agent ID\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (executed_price, cost_paid)\n",
        "        \"\"\"\n",
        "        if direction == 'buy':\n",
        "            # Swap stable for tokens\n",
        "            # Need to compute: given dy_out (order_size), what is dx_in?\n",
        "            # Formula: dx = (k / (y - dy_out)) - x\n",
        "\n",
        "            min_reserve = 1e-6  # Prevent zero\n",
        "            new_reserve_stable = self.k / (self.reserve_token + order_size)\n",
        "            dx = max(self.reserve_stable - new_reserve_stable, min_reserve)\n",
        "\n",
        "            executed_price = dx / order_size\n",
        "\n",
        "            # Update reserves\n",
        "            self.reserve_token += order_size\n",
        "            self.reserve_stable -= dx\n",
        "\n",
        "            cost = dx\n",
        "\n",
        "        else:  # sell\n",
        "            # Swap tokens for stable\n",
        "            # Given dx_in (order_size), compute dy_out\n",
        "            # Formula: dy = y - (k / (x + dx))\n",
        "\n",
        "            min_reserve = 1e-6\n",
        "            new_reserve_token = self.k / (self.reserve_stable + order_size)\n",
        "            dy = max(self.reserve_token - new_reserve_token, min_reserve)\n",
        "\n",
        "            executed_price = dy / order_size\n",
        "\n",
        "            # Update reserves\n",
        "            self.reserve_token -= dy\n",
        "            self.reserve_stable += order_size\n",
        "\n",
        "            cost = -dy  # Negative because we receive stable\n",
        "\n",
        "        # Record trade\n",
        "        self.executed_trades.append({\n",
        "            'agent_id': agent_id,\n",
        "            'direction': direction,\n",
        "            'size': order_size,\n",
        "            'price': executed_price,\n",
        "            'timestamp': len(self.executed_trades)\n",
        "        })\n",
        "\n",
        "        return executed_price, cost\n",
        "\n",
        "    def update_price_history(self):\n",
        "        \"\"\"Update price and volatility tracking.\"\"\"\n",
        "        current_price = self.get_current_price()\n",
        "        self.price_history.append(current_price)\n",
        "\n",
        "        # Compute rolling volatility (last 20 steps)\n",
        "        if len(self.price_history) > 1:\n",
        "            returns = np.diff(np.log(self.price_history[-20:]))\n",
        "            volatility = np.std(returns) if len(returns) > 0 else 0.0\n",
        "        else:\n",
        "            volatility = 0.0\n",
        "\n",
        "        self.volatility_history.append(volatility)\n",
        "\n",
        "        return current_price, volatility\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 5: SIMULATION ENGINE\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class SimulationEngine:\n",
        "    \"\"\"\n",
        "    Orchestrates agent-based simulation across episodes.\n",
        "\n",
        "    Three scenarios:\n",
        "    - A: Rational agents only (baseline)\n",
        "    - B: MARL predators + behavioral prey (APE)\n",
        "    - C: Scenario B + regulatory enforcement\n",
        "\n",
        "    Execution:\n",
        "    - 100 episodes (trading days)\n",
        "    - 250 steps per episode (1-minute resolution, ~4 hours/day)\n",
        "    - Tracks: profits, volatility, cascades, regulatory violations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: SimulationConfig):\n",
        "        self.config = config\n",
        "        np.random.seed(config.random_seed)\n",
        "\n",
        "        self.results = {\n",
        "            'A': [],  # Scenario A results\n",
        "            'B': [],  # Scenario B results\n",
        "            'C': []   # Scenario C results\n",
        "        }\n",
        "\n",
        "    def initialize_agents(self, include_predators: bool = True):\n",
        "        \"\"\"\n",
        "        Create agent population.\n",
        "\n",
        "        Args:\n",
        "            include_predators: If False, scenario A (rational only)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (predators, prey)\n",
        "        \"\"\"\n",
        "        predators = []\n",
        "        prey = []\n",
        "\n",
        "        if include_predators:\n",
        "            for i in range(self.config.n_predators):\n",
        "                predators.append(\n",
        "                    PredatorAgent(i, self.config.initial_balance_predator, self.config)\n",
        "                )\n",
        "\n",
        "        for i in range(self.config.n_prey):\n",
        "            prey.append(\n",
        "                PreyAgent(\n",
        "                    self.config.n_predators + i,\n",
        "                    self.config.initial_balance_prey,\n",
        "                    self.config\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return predators, prey\n",
        "\n",
        "    def run_episode(\n",
        "        self,\n",
        "        episode_num: int,\n",
        "        predators: List[PredatorAgent],\n",
        "        prey: List[PreyAgent],\n",
        "        market: Market,\n",
        "        scenario: str = 'B'\n",
        "    ) -> EpisodeMetrics:\n",
        "        \"\"\"\n",
        "        Execute one trading day (250 steps = 4 hours).\n",
        "\n",
        "        Args:\n",
        "            episode_num: Episode number\n",
        "            predators: List of predator agents\n",
        "            prey: List of prey agents\n",
        "            market: Market instance\n",
        "            scenario: 'A', 'B', or 'C'\n",
        "\n",
        "        Returns:\n",
        "            EpisodeMetrics with statistics\n",
        "        \"\"\"\n",
        "        metrics = EpisodeMetrics(episode_number=episode_num)\n",
        "\n",
        "        initial_predator_wealth = sum(p.get_current_wealth() for p in predators) if predators else 0.0\n",
        "        initial_prey_wealth = sum(p.get_current_wealth() for p in prey)\n",
        "\n",
        "        # Simulate 250 steps\n",
        "        for step in range(self.config.steps_per_episode):\n",
        "\n",
        "            # PREDATOR DECISIONS\n",
        "            for predator in predators:\n",
        "                current_price = market.get_current_price()\n",
        "\n",
        "                # Compute state variables\n",
        "                order_book_imbalance = np.random.normal(0, 1)  # Simplified\n",
        "                prey_panic_level = np.mean([\n",
        "                    1.0 if p.is_panicking else 0.0 for p in prey\n",
        "                ])\n",
        "                market_volatility = market.volatility_history[-1] if market.volatility_history else 0.01\n",
        "\n",
        "                # Get action from policy\n",
        "                order_size, direction = predator.decide_action(\n",
        "                    current_price,\n",
        "                    order_book_imbalance,\n",
        "                    prey_panic_level,\n",
        "                    market_volatility\n",
        "                )\n",
        "\n",
        "                # Execute\n",
        "                executed_price, cost = market.execute_trade(order_size, direction, predator.agent_id)\n",
        "\n",
        "                # Update predator balance\n",
        "                if direction == 'buy':\n",
        "                    predator.balance -= cost\n",
        "                else:\n",
        "                    predator.balance += cost\n",
        "\n",
        "                predator.execute_trade(order_size, direction)\n",
        "                metrics.predator_volume += order_size\n",
        "\n",
        "            # PREY DECISIONS\n",
        "            cascade_triggered = False\n",
        "            panic_count = 0\n",
        "\n",
        "            for prey_agent in prey:\n",
        "                current_price = market.get_current_price()\n",
        "                price_change = market.price_history[-2] - current_price if len(market.price_history) > 1 else 0.0\n",
        "                market_volatility = market.volatility_history[-1] if market.volatility_history else 0.01\n",
        "\n",
        "                will_trade, order_size, direction = prey_agent.decide_action(\n",
        "                    current_price,\n",
        "                    price_change,\n",
        "                    market_volatility\n",
        "                )\n",
        "\n",
        "                if will_trade:\n",
        "                    executed_price, cost = market.execute_trade(order_size, direction, prey_agent.agent_id)\n",
        "\n",
        "                    if direction == 'buy':\n",
        "                        prey_agent.balance -= cost\n",
        "                    else:\n",
        "                        prey_agent.balance += cost\n",
        "\n",
        "                    prey_agent.execute_trade(order_size, direction)\n",
        "                    metrics.prey_volume += order_size\n",
        "\n",
        "                if prey_agent.is_panicking:\n",
        "                    panic_count += 1\n",
        "\n",
        "            # CASCADE DETECTION\n",
        "            panic_fraction = panic_count / len(prey)\n",
        "            if panic_fraction > self.config.cascade_threshold:\n",
        "                cascade_triggered = True\n",
        "                metrics.cascade_events += 1\n",
        "\n",
        "            metrics.panic_selling_count = panic_count\n",
        "\n",
        "            # UPDATE MARKET STATE\n",
        "            current_price, volatility = market.update_price_history()\n",
        "\n",
        "            # REGULATORY ENFORCEMENT (Scenario C)\n",
        "            if scenario == 'C':\n",
        "                # Fine predators for suspicious behavior (high cancellation rate)\n",
        "                cancellation_rate = np.random.uniform(0.5, 0.95)  # Predators try to evade\n",
        "\n",
        "                if cancellation_rate > self.config.cancellation_threshold:\n",
        "                    metrics.violations_detected += 1\n",
        "                    metrics.regulation_fines += self.config.fine_magnitude\n",
        "\n",
        "                    # Apply fines to predators\n",
        "                    if predators:\n",
        "                        fine_per_predator = self.config.fine_magnitude / len(predators)\n",
        "                        for predator in predators:\n",
        "                            predator.balance -= fine_per_predator\n",
        "\n",
        "        # END-OF-EPISODE CALCULATION\n",
        "        final_predator_wealth = sum(p.get_current_wealth() for p in predators) if predators else 0.0\n",
        "        final_prey_wealth = sum(p.get_current_wealth() for p in prey)\n",
        "\n",
        "        metrics.predator_profit = final_predator_wealth - initial_predator_wealth\n",
        "        metrics.prey_loss = -(final_prey_wealth - initial_prey_wealth)\n",
        "        metrics.market_volatility = np.mean(market.volatility_history[-50:]) if len(market.volatility_history) > 50 else 0.0\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def run_scenario(self, scenario: str) -> List[EpisodeMetrics]:\n",
        "        \"\"\"\n",
        "        Run complete scenario (100 episodes).\n",
        "\n",
        "        Args:\n",
        "            scenario: 'A' (rational), 'B' (predatory), or 'C' (regulated)\n",
        "\n",
        "        Returns:\n",
        "            List of EpisodeMetrics\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Running Scenario {scenario}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        include_predators = (scenario in ['B', 'C'])\n",
        "        predators, prey = self.initialize_agents(include_predators)\n",
        "        market = Market(self.config)\n",
        "\n",
        "        episode_results = []\n",
        "\n",
        "        for episode in range(self.config.n_episodes):\n",
        "            metrics = self.run_episode(\n",
        "                episode,\n",
        "                predators,\n",
        "                prey,\n",
        "                market,\n",
        "                scenario=scenario\n",
        "            )\n",
        "\n",
        "            episode_results.append(metrics)\n",
        "\n",
        "            if (episode + 1) % 10 == 0:\n",
        "                avg_predator_profit = np.mean([\n",
        "                    m.predator_profit for m in episode_results[-10:]\n",
        "                ])\n",
        "                avg_volatility = np.mean([\n",
        "                    m.market_volatility for m in episode_results[-10:]\n",
        "                ])\n",
        "                print(f\"Episode {episode+1:3d} | \"\n",
        "                      f\"Predator Profit: ${avg_predator_profit:8.2f} | \"\n",
        "                      f\"Volatility: {avg_volatility:6.2%}\")\n",
        "\n",
        "        self.results[scenario] = episode_results\n",
        "        return episode_results\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 6: ANALYSIS & RESULTS AGGREGATION\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class ResultsAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze simulation results across scenarios.\n",
        "    Compute statistics, generate tables, validate propositions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, simulator: SimulationEngine):\n",
        "        self.simulator = simulator\n",
        "\n",
        "    def summarize_scenario(self, scenario: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Compute summary statistics for scenario.\n",
        "\n",
        "        Args:\n",
        "            scenario: 'A', 'B', or 'C'\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of aggregate metrics\n",
        "        \"\"\"\n",
        "        results = self.simulator.results[scenario]\n",
        "\n",
        "        predator_profits = [m.predator_profit for m in results]\n",
        "        prey_losses = [m.prey_loss for m in results]\n",
        "        volatilities = [m.market_volatility for m in results]\n",
        "        cascades = [m.cascade_events for m in results]\n",
        "\n",
        "        return {\n",
        "            'scenario': scenario,\n",
        "            'mean_predator_daily_profit': np.mean(predator_profits),\n",
        "            'total_predator_profit': np.sum(predator_profits),\n",
        "            'mean_prey_daily_loss': np.mean(prey_losses),\n",
        "            'total_prey_loss': np.sum(prey_losses),\n",
        "            'mean_volatility': np.mean(volatilities),\n",
        "            'total_cascades': np.sum(cascades),\n",
        "            'median_cascades_per_episode': np.median(cascades),\n",
        "        }\n",
        "\n",
        "    def generate_results_table(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Generate comparison table across all scenarios.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with results\n",
        "        \"\"\"\n",
        "        summaries = {\n",
        "            scenario: self.summarize_scenario(scenario)\n",
        "            for scenario in ['A', 'B', 'C']\n",
        "        }\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Scenario A (Rational)': {\n",
        "                'Predator Daily Profit': summaries['A']['mean_predator_daily_profit'],\n",
        "                'Predator Total Profit': summaries['A']['total_predator_profit'],\n",
        "                'Prey Daily Loss': summaries['A']['mean_prey_daily_loss'],\n",
        "                'Prey Total Loss': summaries['A']['total_prey_loss'],\n",
        "                'Mean Volatility': summaries['A']['mean_volatility'],\n",
        "                'Total Cascades': summaries['A']['total_cascades'],\n",
        "            },\n",
        "            'Scenario B (Predatory)': {\n",
        "                'Predator Daily Profit': summaries['B']['mean_predator_daily_profit'],\n",
        "                'Predator Total Profit': summaries['B']['total_predator_profit'],\n",
        "                'Prey Daily Loss': summaries['B']['mean_prey_daily_loss'],\n",
        "                'Prey Total Loss': summaries['B']['total_prey_loss'],\n",
        "                'Mean Volatility': summaries['B']['mean_volatility'],\n",
        "                'Total Cascades': summaries['B']['total_cascades'],\n",
        "            },\n",
        "            'Scenario C (Regulated)': {\n",
        "                'Predator Daily Profit': summaries['C']['mean_predator_daily_profit'],\n",
        "                'Predator Total Profit': summaries['C']['total_predator_profit'],\n",
        "                'Prey Daily Loss': summaries['C']['mean_prey_daily_loss'],\n",
        "                'Prey Total Loss': summaries['C']['total_prey_loss'],\n",
        "                'Mean Volatility': summaries['C']['mean_volatility'],\n",
        "                'Total Cascades': summaries['C']['total_cascades'],\n",
        "            }\n",
        "        })\n",
        "\n",
        "        return df\n",
        "\n",
        "    def validate_propositions(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Check Proposition 1 & 2 hypotheses.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of validation results\n",
        "        \"\"\"\n",
        "        summary_a = self.summarize_scenario('A')\n",
        "        summary_b = self.summarize_scenario('B')\n",
        "        summary_c = self.summarize_scenario('C')\n",
        "\n",
        "        # Proposition 1: Volatility Induction\n",
        "        volatility_increase = (summary_b['mean_volatility'] - summary_a['mean_volatility']) / summary_a['mean_volatility']\n",
        "        alpha_increase = (summary_b['mean_predator_daily_profit'] - summary_a['mean_predator_daily_profit']) / summary_a['mean_predator_daily_profit']\n",
        "\n",
        "        # Proposition 2: Information Cascades\n",
        "        cascade_increase = (summary_b['total_cascades'] - summary_a['total_cascades']) / (summary_a['total_cascades'] + 1)\n",
        "\n",
        "        # Regulatory Effectiveness\n",
        "        profit_reduction = (summary_b['mean_predator_daily_profit'] - summary_c['mean_predator_daily_profit']) / summary_b['mean_predator_daily_profit']\n",
        "        cascade_reduction = (summary_b['total_cascades'] - summary_c['total_cascades']) / (summary_b['total_cascades'] + 1)\n",
        "\n",
        "        return {\n",
        "            'proposition_1': {\n",
        "                'volatility_increase_pct': volatility_increase * 100,\n",
        "                'alpha_increase_pct': alpha_increase * 100,\n",
        "                'validated': volatility_increase > 1.0 and alpha_increase > 10.0\n",
        "            },\n",
        "            'proposition_2': {\n",
        "                'cascade_increase_pct': cascade_increase * 100,\n",
        "                'validated': cascade_increase > 10.0\n",
        "            },\n",
        "            'regulatory_gap': {\n",
        "                'profit_reduction_pct': profit_reduction * 100,\n",
        "                'cascade_reduction_pct': cascade_reduction * 100,\n",
        "                'residual_alpha_daily': summary_c['mean_predator_daily_profit'],\n",
        "                'insufficient_enforcement': summary_c['mean_predator_daily_profit'] > 0.0\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# SECTION 7: MAIN EXECUTION\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Execute complete simulation suite.\n",
        "\n",
        "    1. Initialize configuration\n",
        "    2. Run three scenarios (A, B, C)\n",
        "    3. Analyze results\n",
        "    4. Validate propositions\n",
        "    5. Output results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ALGORITHMIC PREDATORY EQUILIBRIUM (APE) SIMULATION\")\n",
        "    print(\"Publication-Ready Code\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # CONFIGURATION\n",
        "    config = SimulationConfig(\n",
        "        n_episodes=100,\n",
        "        steps_per_episode=250,\n",
        "        loss_aversion_lambda=2.25,\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Episodes: {config.n_episodes}\")\n",
        "    print(f\"  Steps/Episode: {config.steps_per_episode}\")\n",
        "    print(f\"  Loss Aversion (λ): {config.loss_aversion_lambda}\")\n",
        "    print(f\"  Predators: {config.n_predators}\")\n",
        "    print(f\"  Prey: {config.n_prey}\")\n",
        "\n",
        "    # SIMULATION ENGINE\n",
        "    engine = SimulationEngine(config)\n",
        "\n",
        "    # RUN SCENARIOS\n",
        "    engine.run_scenario('A')\n",
        "    engine.run_scenario('B')\n",
        "    engine.run_scenario('C')\n",
        "\n",
        "    # ANALYSIS\n",
        "    analyzer = ResultsAnalyzer(engine)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results_table = analyzer.generate_results_table()\n",
        "    print(\"\\n\" + results_table.to_string())\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PROPOSITION VALIDATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    validation = analyzer.validate_propositions()\n",
        "\n",
        "    print(\"\\nProposition 1 (Volatility Induction):\")\n",
        "    print(f\"  ✓ Volatility Increase: {validation['proposition_1']['volatility_increase_pct']:.1f}%\")\n",
        "    print(f\"  ✓ Alpha Increase: {validation['proposition_1']['alpha_increase_pct']:.1f}%\")\n",
        "    print(f\"  ✓ Validated: {validation['proposition_1']['validated']}\")\n",
        "\n",
        "    print(\"\\nProposition 2 (Information Cascades):\")\n",
        "    print(f\"  ✓ Cascade Increase: {validation['proposition_2']['cascade_increase_pct']:.1f}%\")\n",
        "    print(f\"  ✓ Validated: {validation['proposition_2']['validated']}\")\n",
        "\n",
        "    print(\"\\nRegulatory Gap:\")\n",
        "    print(f\"  ✓ Profit Reduction (Enforcement): {validation['regulatory_gap']['profit_reduction_pct']:.1f}%\")\n",
        "    print(f\"  ✓ Cascade Reduction: {validation['regulatory_gap']['cascade_reduction_pct']:.1f}%\")\n",
        "    print(f\"  ✓ Residual Alpha (Daily): ${validation['regulatory_gap']['residual_alpha_daily']:.2f}\")\n",
        "    print(f\"  ✓ Insufficient Enforcement: {validation['regulatory_gap']['insufficient_enforcement']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    return engine, analyzer, validation\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    engine, analyzer, validation = main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4VVlSNFOLwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8d3677d2",
        "outputId": "e6accd5d-791d-4d2b-c6ca-64bc5ec24021"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Ensure the main function has been run and 'analyzer' is available\n",
        "# If not, run it:\n",
        "# engine, analyzer, validation = main()\n",
        "\n",
        "def plot_predator_profit(analyzer):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for scenario, results in analyzer.simulator.results.items():\n",
        "        profits = [m.predator_profit for m in results]\n",
        "        episodes = [m.episode_number for m in results]\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=episodes,\n",
        "            y=profits,\n",
        "            mode='lines',\n",
        "            name=f'Scenario {scenario} Predator Profit'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Predator Profit Across Scenarios (Interactive)',\n",
        "        xaxis_title='Episode Number',\n",
        "        yaxis_title='Predator Profit',\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "def plot_market_volatility(analyzer):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for scenario, results in analyzer.simulator.results.items():\n",
        "        volatilities = [m.market_volatility for m in results]\n",
        "        episodes = [m.episode_number for m in results]\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=episodes,\n",
        "            y=volatilities,\n",
        "            mode='lines',\n",
        "            name=f'Scenario {scenario} Market Volatility'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Market Volatility Across Scenarios (Interactive)',\n",
        "        xaxis_title='Episode Number',\n",
        "        yaxis_title='Market Volatility',\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "# Call the plotting functions\n",
        "if 'analyzer' in locals():\n",
        "    plot_predator_profit(analyzer)\n",
        "    plot_market_volatility(analyzer)\n",
        "else:\n",
        "    print(\"Please run the main simulation first to get the 'analyzer' object.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2bed62e4-8410-4c27-b7ba-26e0201653f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2bed62e4-8410-4c27-b7ba-26e0201653f8\")) {                    Plotly.newPlot(                        \"2bed62e4-8410-4c27-b7ba-26e0201653f8\",                        [{\"mode\":\"lines\",\"name\":\"Scenario A Predator Profit\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario B Predator Profit\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-6916.678073220723,-99.42932582802314,-114.84736819795398,-131.43301137116032,-147.21047570442624,-163.76266823385959,-180.74198182450255,-197.65779061294234,-215.80917522845994,-233.37312575818942,-249.75342389952675,-266.4597202964251,-284.7915607580708,-303.18754177021947,-322.71128360586954,-340.1351100585198,-356.34622294320434,-376.0613497947561,-391.6764517441716,-407.3737072136082,-417.75740860038786,-430.9844274779389,-449.7577428924469,-468.8762125281137,-489.7946482626503,-508.5791301909685,-525.7213741128344,-542.0293354714577,-557.1958761735441,-576.274452937867,-591.719091240855,-607.740289801739,-621.0214339123086,-635.0390869744697,-649.6821942696915,-654.1521920315972,-661.4690026067947,-664.1892540194094,-670.9960222443151,-663.2661802573311,-661.4152742113074,-672.4908161855201,-676.141123354515,-690.0377300941145,-699.3823241694845,-699.5303237696098,-707.0296762564976,-725.426852877099,-733.6668800487387,-734.7806059405702,-738.961699595864,-747.1331231530639,-749.6650164576931,-751.017717105613,-750.5527415722645,-756.90762407894,-765.0637035420368,-766.1059020963439,-772.9493500856042,-771.5328468597945,-767.9329767832896,-764.7844625309808,-761.0284547622869,-761.427933322957,-768.2710794147788,-770.1909803878443,-768.5837968134874,-774.9312087508952,-775.8152156546785,-774.8170867680237,-777.122022592077,-782.7432647765891,-779.3133035171486,-780.8329442255781,-788.3538638903556,-786.4374414051927,-791.151642925608,-791.8426133378234,-793.3191478672379,-793.3877540240355,-795.2392269548509,-800.9408719182175,-803.8329471560792,-805.8167822528412,-815.359221912724,-814.9930229025485,-816.919429234782,-817.6779225068094,-823.8347656497936,-821.7893472606374,-823.6455438568373,-825.0511247223476,-821.7606249223827,-821.7442217166463,-823.3777511261069,-823.9036506193952,-825.4084066776413,-833.0663002134461,-834.1952938077447,-837.4027220722637],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario C Predator Profit\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-9353.310843527957,-2401.6408736827325,-3015.9152205086175,-2430.9375636697605,-3246.9862975647357,-3262.2983110814384,-3679.6831138251837,-2496.654612788956,-3313.910925495471,-2129.1919089367,-2846.3668863930434,-2162.5104216731925,-2680.206040226498,-3198.498472887615,-3222.064987500278,-2138.4781422862143,-3457.183851198388,-2975.06636169806,-3690.070641334867,-2804.4704497406783,-3122.9904177201606,-2441.0413592738405,-2860.1991026544565,-2975.359026951992,-3391.2230126446375,-3805.9043453139893,-3220.9010267504054,-3429.950990401878,-3742.029851770538,-4050.3635802970093,-3569.470638250903,-3185.325033280751,-3406.3640715403308,-3123.256647062197,-3530.4005037965544,-3945.203113563708,-3755.1926525703457,-4371.981255163788,-3778.1535549804394,-3979.338007787941,-3185.0578170975205,-3493.060789899231,-3497.6353842305543,-3202.1856748297578,-3505.200690136,-3308.298221998266,-3222.7961321655603,-3529.222691377654,-4133.859883361583,-4034.16721932753,-3836.9470083185006,-2840.3478630515747,-3152.0861082973715,-3358.6584312419873,-3165.0098591850838,-2973.044116453646,-2970.7173631642363,-3776.343308631447,-2975.2040154125134,-3873.3416314275237,-3679.0447605986847,-3384.231239215471,-3286.25592490306,-3280.763301063387,-3885.31121531775,-3392.2509504756017,-3796.938430932205,-3698.3468589336844,-3303.4540692455485,-3501.5272349803126,-3908.0540406793007,-3418.942504782841,-3826.1850512028323,-3727.2245450541377,-2925.7499356003536,-3223.2382894881302,-3518.0475359880365,-3307.7068915257114,-3010.6364884432987,-3909.0068663848797,-3410.2884442009963,-2815.56401117146,-3116.5043251368916,-4517.204761148372,-3126.487080673629,-3733.7224536639405,-3734.1871647356893,-4737.684807185142,-4641.3847927779425,-4442.892128839914,-3939.2730933549465,-2342.6572525642114,-2846.952742005931,-4052.445649841742,-3158.967764134286,-4356.405562093132,-3162.1219404875883,-3761.3216607756913,-2459.412678507855,-3457.0420904495404],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Predator Profit Across Scenarios (Interactive)\"},\"xaxis\":{\"title\":{\"text\":\"Episode Number\"}},\"yaxis\":{\"title\":{\"text\":\"Predator Profit\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2bed62e4-8410-4c27-b7ba-26e0201653f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"01e1582e-329f-4e1d-b97c-d52ac7333e8a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"01e1582e-329f-4e1d-b97c-d52ac7333e8a\")) {                    Plotly.newPlot(                        \"01e1582e-329f-4e1d-b97c-d52ac7333e8a\",                        [{\"mode\":\"lines\",\"name\":\"Scenario A Market Volatility\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.003059637488399835,0.0033509315020502158,0.0013461900856093544,0.004720130478553017,0.002584759913234373,0.0044432593047946225,0.005575768923392664,0.0020400114643746923,0.0015089631491739949,0.0035113008124053506,0.005766053103849251,0.004852490480640897,0.002073170000826837,0.0023462294676777516,0.0048890977550261686,0.0032273204853528028,0.002952335584055487,0.004613913346008411,0.001770470442411692,0.0012404653616659737,0.004297352105312272,0.002366209127677141,0.006954505263212367,0.002647420522178156,0.0036462152522408354,0.007322134222507648,0.0030574512738333628,0.0016688036101172399,0.003460056870405609,0.006346388524410936,0.007061116505781923,0.005805152818892199,0.002340705698483476,0.002209487404131908,0.004649716276981076,0.0015379287045221392,0.0017053795077527289,0.001733007035215499,0.006816229878206079,0.005695740339984281,0.006897653283053309,0.00798999114040526,0.004471075810983425,0.005817748235196191,0.002625723734627409,0.007583147932730292,0.005877079903764087,0.0035714041861189417,0.002404244025527715,0.0029706928220957396,0.0026856771935293076,0.0036574627446758694,0.001400945336448271,0.0077826600767396115,0.0019204861080556216,0.005463161798639289,0.0029842988642325473,0.0009022589865724798,0.005470077116571126,0.006598971374469057,0.002695593881522966,0.006864661768068733,0.002782843842792393,0.0024372595808768464,0.002363676127787119,0.003823255344645573,0.004134023658852581,0.001961487624450738,0.005709318748468319,0.004977515151402685,0.0027913420083473263,0.003324482159928445,0.0028747504728306723,0.0053592402902460454,0.009186006438544095,0.004867599151587817,0.0019230118901389364,0.00220932910898013,0.0035302389931641445,0.009017567816402457,0.0021732692097882634,0.003660988044964488,0.0019746205817219344,0.006832039103991547,0.006171805471424776,0.002139132781398507,0.005499533239517382,0.002254869423409254,0.0018776419189421253,0.005278813303856506,0.004599435038560374,0.005209668525099159,0.001402241027256089,0.00414284922330479,0.0076511395518337995,0.0055195276201537805,0.006757974117592421,0.003565125347321872,0.005791693411749661,0.008896107220690206],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario B Market Volatility\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.003792538049413581,0.00418162232585313,0.005908033732247283,0.0017766526583781145,0.00406071752506803,0.0021699799105463014,0.003219450608059706,0.004211077469292181,0.0027814782771872232,0.0013134748188349346,0.0010004526376983212,0.0014267128069700816,0.003234812080869523,0.005245453985573246,0.0037536328468084318,0.003862882235853945,0.004249917573775175,0.001141568494914771,0.003711076356316692,0.001773883367141075,0.001423650033834272,0.0035118589542127822,0.004427378385960347,0.00696419297788724,0.002538791368506807,0.0020784142720451084,0.002243438711087736,0.00252390965848767,0.008500487832338614,0.002159517748937985,0.0018483795821441554,0.001402933277888084,0.006800471327820405,0.0021021892729782784,0.0026977262540413575,0.004761617317971806,0.004944972525933994,0.005250787433600227,0.0019846373774941094,0.0013094690555771563,0.007683579770567522,0.002388139244774528,0.005418126428274555,0.0024371609107991534,0.004088196181249358,0.002154096669935803,0.004939688804717228,0.003617451183201049,0.0019510581937919793,0.003269985276675455,0.004601015391234763,0.0027795535215346884,0.0048274541438971955,0.0028564917830696313,0.004734788038700142,0.001586621193834105,0.0028649160048196598,0.0026419362342870044,0.0018267059149974282,0.0014651934559593697,0.0035744180248019537,0.004731227700573529,0.0060535191233114325,0.0018020249705316973,0.002590948697323672,0.002295202445485232,0.0059042757653237285,0.0060810061082720935,0.004270030750409866,0.0019141528989394898,0.004333541801860492,0.0017779229690739228,0.002429050519872845,0.0018779914607861318,0.006186520315038642,0.00492339812811971,0.005978732779854314,0.007202866116073963,0.006408481451825149,0.001995898399448898,0.007044037787339685,0.0032847967039557036,0.0065984357388218584,0.006908086726158827,0.0010900741054702533,0.0031244183541693387,0.004807920515291694,0.0032501655828598066,0.006524326330204995,0.0038703756299706383,0.0031959533417373538,0.0032317384174242623,0.0063596235704144865,0.00285883829983649,0.00361103498202601,0.0013907347865783337,0.0026371148900624173,0.00614005965940857,0.004423473980174654,0.00490897733292654],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario C Market Volatility\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.00365169349110588,0.0055396904441139105,0.002036914542151243,0.0038140534541110066,0.0019427553122659403,0.007523417273016553,0.004827535502697615,0.0032607400981099605,0.004278588519234277,0.002641163721741787,0.0035875445496903542,0.006815095021791126,0.003650501700096221,0.007579291036996093,0.006327884426619025,0.0044349649100967345,0.008317975530060064,0.001173849372424826,0.0020336773799666547,0.00322984602283982,0.010941779645629077,0.006301192013299584,0.003478085819423747,0.004016913803159929,0.0064850685722567325,0.003075439164508991,0.0010742270530534092,0.0013082953505216448,0.002347092428406742,0.007006453131189334,0.005984744208525062,0.005274011417279437,0.004543349412716461,0.0009622518745533813,0.0024816179603278526,0.0011779801597496453,0.007333864812507989,0.004217006835804529,0.004167626671968333,0.0014391927717644333,0.007232945526188472,0.002247045009109891,0.007669188563598416,0.003544540626780568,0.0037566025785752415,0.005237882130167107,0.004414809456096841,0.006118091664140063,0.002963324571546005,0.0013109464527251253,0.0056565868094136055,0.004284372530448193,0.0024730071164516545,0.003055027928586953,0.006052605363996626,0.002876975511927722,0.004254729593816297,0.0022091162594997053,0.007425416728881637,0.0013211936429623193,0.0026341797138531185,0.001819136352709783,0.0019923791818366047,0.005735936428608228,0.005156434373957249,0.005905327864983068,0.0015599181136680062,0.007197763943332892,0.0018378325610908317,0.0027443859036209075,0.007032073699684783,0.006507187685130512,0.0017330774838801935,0.002043600479657898,0.0017161218223936633,0.0050821986670383165,0.0037082668197196134,0.0041929557475702565,0.001060377884345673,0.0030846715110311802,0.0016961064085008234,0.005403159402170485,0.006339265312860261,0.0024791026964184133,0.004987148147174864,0.003959260233850838,0.004694495425958924,0.002490295070293061,0.003910188748372233,0.008324247861992606,0.0013255745860004523,0.0047100160393265065,0.006195934220218397,0.004941328146564188,0.0013267101781084356,0.002993812909977895,0.007050796009255939,0.0066741018419080025,0.005599133349662525,0.0013048257131944418],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Market Volatility Across Scenarios (Interactive)\"},\"xaxis\":{\"title\":{\"text\":\"Episode Number\"}},\"yaxis\":{\"title\":{\"text\":\"Market Volatility\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('01e1582e-329f-4e1d-b97c-d52ac7333e8a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sX_aDJkwO4pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "d01f7372",
        "outputId": "d3afe6ca-d680-4976-858b-c96e11861bc7"
      },
      "source": [
        "def plot_prey_loss(analyzer):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for scenario, results in analyzer.simulator.results.items():\n",
        "        prey_losses = [-m.prey_loss for m in results] # Negative of prey_loss to show profit/loss from prey perspective\n",
        "        episodes = [m.episode_number for m in results]\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=episodes,\n",
        "            y=prey_losses,\n",
        "            mode='lines',\n",
        "            name=f'Scenario {scenario} Prey PnL'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Prey Profit/Loss Across Scenarios (Interactive)',\n",
        "        xaxis_title='Episode Number',\n",
        "        yaxis_title='Prey Profit/Loss',\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "# Call the new plotting function\n",
        "if 'analyzer' in locals():\n",
        "    plot_prey_loss(analyzer)\n",
        "else:\n",
        "    print(\"Please run the main simulation first to get the 'analyzer' object.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"795c72ea-48d1-41f9-9c8f-5d0227aed48f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"795c72ea-48d1-41f9-9c8f-5d0227aed48f\")) {                    Plotly.newPlot(                        \"795c72ea-48d1-41f9-9c8f-5d0227aed48f\",                        [{\"mode\":\"lines\",\"name\":\"Scenario A Prey PnL\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-57334.683881399505,-54451.800166078036,-50750.50265019297,-51234.8793545058,-49292.881657828344,-46807.723978063004,-45240.21038869553,-46359.400323207316,-43660.45295604679,-43198.855632782564,-42204.523696375196,-42428.5925479033,-39881.47754868143,-40819.3721029287,-39687.6006284249,-39096.33849833661,-37947.675949601224,-36854.97795050102,-36060.20954781538,-35872.31889065367,-34921.63083112496,-35763.97322677984,-34863.102998076356,-34483.69109636347,-33998.75024248229,-33276.868558826856,-32082.40181847196,-33069.73627974861,-32138.774241815787,-31427.092504018452,-31313.21795133059,-30691.93039457267,-29953.857292428846,-30141.41815243056,-30496.113826908404,-29256.494612372248,-30078.915793654975,-28385.066102986224,-28380.173254530877,-29878.26948929322,-28552.550872305408,-28724.098823791835,-28601.057062555337,-28759.415362647967,-27394.06457409775,-28964.906982694287,-28427.76523890975,-28232.516393380472,-28191.63767069881,-27070.549261816544,-27485.911196467932,-27525.201291388832,-27701.37680399418,-27760.532316981815,-28000.67974833818,-27714.80841212487,-27454.739992390154,-27479.92128864699,-27013.07225869503,-26930.563191502355,-27154.025823609205,-27266.655670570442,-26241.686510781292,-27427.523209691048,-26660.09360253904,-26645.580154874362,-27045.02813390782,-27132.403598372824,-26394.717192665208,-26820.79942582408,-27052.09554487141,-26756.549110461958,-26872.40909238858,-26892.90877139801,-27085.754102629144,-26502.287891404238,-25635.870431634132,-26168.467923693825,-26216.40689737769,-27078.598627976608,-25998.39889180567,-26558.51866539754,-26738.885635267012,-26495.875077990815,-26647.08162198635,-26677.242038890254,-25757.43866789667,-26743.91818579426,-26553.997679232154,-26316.75348985754,-26163.982220854145,-25631.377224543132,-25641.072466865182,-26246.11716481438,-25638.002533877734,-25368.709704868495,-25682.022188933566,-25245.376880894415,-25186.025539793074,-25765.503569912165],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario B Prey PnL\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-61437.73523050628,-58355.48424517753,-57056.563068002346,-56446.049684656085,-53162.33930637699,-53123.43849979469,-51525.51028325851,-49044.30002535827,-49233.12416475359,-46923.17598302942,-46737.4429019182,-46397.606430683634,-44983.299292660784,-44409.1986571718,-43018.29985604319,-41247.028014830896,-41783.05298533931,-40967.1631277703,-40452.72249856056,-39048.717021954595,-39217.04355159635,-38485.233332274365,-38156.249963517184,-37431.795497521525,-37873.89008883666,-37370.702037156094,-36732.33097734698,-35427.25190247013,-35222.977624400286,-35279.71008597757,-34612.7888651595,-34354.35079068062,-34042.669178543845,-33244.25725095626,-33091.283850158565,-33122.25688831275,-32251.189430543454,-32425.70993574825,-32353.10530928173,-31879.03634786443,-32786.93239295692,-31956.137140730163,-31439.423706210684,-31760.607381644193,-32109.562516615726,-31892.86124121654,-31121.494824129157,-32319.66943244799,-30466.759039579658,-31417.859126226278,-31214.10435295757,-30531.42138852901,-30210.097414806485,-31747.96589447139,-30985.718542635208,-30705.324743034318,-31098.64588632621,-31308.941548316274,-30426.184712426737,-29775.944431175478,-29863.946293565445,-30878.60736462893,-30956.901836295612,-30362.519183101133,-30239.06982036354,-30680.002613825724,-30114.74835117068,-30059.503535975236,-30199.362228079233,-30428.211034233682,-30617.09477586858,-30200.572223342024,-30149.006761203054,-30055.446471943986,-29865.53852273943,-30275.843928770628,-30048.083633664995,-30441.830829318147,-30126.419902818743,-29555.021742284298,-30813.156106424052,-29899.17352464283,-30412.557909640484,-29807.079984119628,-30231.948853358626,-30260.720028351527,-29248.073917162605,-28971.257067815866,-29521.56578255957,-30677.422419657465,-29110.60534254415,-28742.790471804794,-29478.35983746918,-28729.737082182895,-29217.50598209817,-28902.115365801845,-29955.102305552922,-28852.20736349281,-29554.049904569518,-29126.03647990944],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Scenario C Prey PnL\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[-61308.8299508066,-57663.83394363975,-57169.08082170405,-55242.280314358446,-54407.65073273241,-53053.91629030445,-50438.43176819064,-50443.61673764011,-49403.154245068145,-47314.58491878596,-46644.98715180141,-44884.21542375267,-45589.58190797898,-44702.63014860952,-43741.16271950945,-42405.56531974906,-41366.53527874977,-40179.663971957285,-40549.24821181374,-40310.60927832103,-39168.79215902998,-38112.06888569426,-37875.7426532699,-36804.23550947453,-37797.49593224563,-37619.876072885,-36261.16873630369,-34899.19199856743,-35229.13038581982,-35567.704790333286,-35312.70667411038,-33759.401022799546,-34421.04336253833,-34023.50587801845,-33199.74842479685,-33537.66774087609,-33089.91976891132,-31834.11124247336,-32024.79867390194,-32123.399513994576,-31781.04199620383,-32581.96509937779,-32157.48883455433,-32163.592111193575,-32115.498805738054,-31841.75604269211,-31034.081048711203,-31129.52275461727,-30503.199057309423,-31279.295939363074,-30821.011509239674,-31739.02031142218,-31006.4581971711,-31248.142734196037,-30840.873431078624,-29995.617622395977,-29903.917017552536,-30479.503383797593,-30670.432318812702,-29829.19835485192,-29824.89404796716,-30875.295152339153,-30167.40645105671,-29818.545140427537,-30495.65247552609,-30228.8686259361,-30622.269960843958,-29431.045469167177,-29848.97865095781,-29509.71656573331,-30262.458074647468,-29741.38552761823,-29604.702189106494,-29178.011031337548,-29456.090022798162,-29104.76190441195,-29090.09354457259,-29800.04674177384,-29698.470336113125,-29382.350427199155,-29320.23437266331,-29726.802515800577,-29666.339004196692,-29508.440363192465,-29500.28519063769,-29632.139728321694,-29912.703538426198,-28963.25485080527,-28918.52544906456,-29632.63923247531,-28573.847014605533,-29683.854764830787,-29051.919189644046,-29050.100349285174,-28837.84063238371,-29189.765356337186,-28508.180933729745,-28863.239653209224,-28773.264241983183,-28123.42193725612],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Prey Profit\\u002fLoss Across Scenarios (Interactive)\"},\"xaxis\":{\"title\":{\"text\":\"Episode Number\"}},\"yaxis\":{\"title\":{\"text\":\"Prey Profit\\u002fLoss\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('795c72ea-48d1-41f9-9c8f-5d0227aed48f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b39e8dc0"
      },
      "source": [
        "### Simulation Results Analysis\n",
        "\n",
        "The simulation aimed to model an Algorithmic Predatory Equilibrium (APE) across three scenarios: rational agents (A), MARL predators with behavioral prey (B), and regulated predatory behavior (C).\n",
        "\n",
        "**Key Findings from the Results Table:**\n",
        "\n",
        "| Metric                   | Scenario A (Rational) | Scenario B (Predatory) | Scenario C (Regulated) |\n",
        "|:-------------------------|----------------------:|-----------------------:|-----------------------:|\n",
        "| Predator Daily Profit    |                  0.00 |              -695.94 |             -3440.19 |\n",
        "| Predator Total Profit    |                  0.00 |            -69593.72 |            -344018.71 |\n",
        "| Prey Daily Loss          |               31278.77 |             34898.31 |             34721.81 |\n",
        "| Prey Total Loss          |             3127877.10 |           3489831.06 |           3472180.89 |\n",
        "| Mean Volatility          |                  0.0041 |                 0.0037 |                 0.0041 |\n",
        "| Total Cascades           |               24995.00 |             24922.00 |             24861.00 |\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "1.  **Predator Profit:**\n",
        "    *   In Scenario A (Rational), predators show zero profit, as expected, because there are no behavioral anomalies to exploit. They are not actually 'predators' in this scenario, simply other rational agents.\n",
        "    *   Surprisingly, in Scenario B (Predatory) and Scenario C (Regulated), predators exhibit significant *losses* rather than profits. This is contrary to the initial expectation that predators would profit from behavioral prey. The simulation's current parametrization seems to result in predators losing money even when attempting to exploit the market. This suggests that the simplified policy gradient for predators might not be effective enough to generate profits under the current market conditions and agent behaviors, or that the costs associated with trading (e.g., gas costs, market impact) outweigh potential gains.\n",
        "\n",
        "2.  **Prey Loss:**\n",
        "    *   Prey agents consistently incur losses across all scenarios. Their losses are substantial, in the order of millions over the total simulation steps.\n",
        "    *   The difference in prey losses between Scenario A and Scenario B/C is relatively small. This implies that while predators are losing money, the behavioral aspects of prey (loss aversion, panic selling) still contribute to their overall losses, regardless of whether predators are actively exploiting them effectively or not.\n",
        "\n",
        "3.  **Market Volatility:**\n",
        "    *   Mean market volatility remains low and relatively consistent across all three scenarios (around 0.4%).\n",
        "    *   This is another unexpected outcome. Proposition 1 posits that predators should *increase* volatility. The current results show a slight *decrease* in volatility in Scenario B compared to A, and then a return to Scenario A levels in Scenario C. This contradicts the hypothesis that MARL agents induce volatility.\n",
        "\n",
        "4.  **Information Cascades:**\n",
        "    *   The 'Total Cascades' metric, representing panic-selling events, is very high across all scenarios (around 25,000 events).\n",
        "    *   Similar to volatility, there is no significant increase in cascades from Scenario A to B, and only a very minor reduction in C. This contradicts Proposition 2, which states that predatory agents induce more information cascades.\n",
        "\n",
        "**Proposition Validation:**\n",
        "\n",
        "*   **Proposition 1 (Volatility Induction):**\n",
        "    *   `Volatility Increase: -10.3%` (Expected positive increase)\n",
        "    *   `Alpha Increase: -inf%` (Expected positive increase, but predators are losing money)\n",
        "    *   `Validated: False`\n",
        "    *   The simulation results do **not** validate Proposition 1. Predators are not effectively inducing volatility or generating alpha (profit) from their strategies under the current parameters.\n",
        "\n",
        "*   **Proposition 2 (Information Cascades):**\n",
        "    *   `Cascade Increase: -0.3%` (Expected positive increase)\n",
        "    *   `Validated: False`\n",
        "    *   The simulation results do **not** validate Proposition 2. There is no observed increase in information cascades due to the presence of predatory agents.\n",
        "\n",
        "*   **Regulatory Gap:**\n",
        "    *   `Profit Reduction (Enforcement): -394.3%` (Indicates predators lost even more money in regulated scenario)\n",
        "    *   `Cascade Reduction: 0.2%` (Minimal reduction)\n",
        "    *   `Residual Alpha (Daily): $-3440.19` (Still losing money)\n",
        "    *   `Insufficient Enforcement: False`\n",
        "    *   The regulatory intervention in Scenario C seems to have exacerbated predator losses even further, rather than simply reducing their predatory profits. This is likely due to the fine mechanism affecting agents who are already struggling to profit. The enforcement is deemed 'insufficient' (returning `False` for `insufficient_enforcement`) because predators are not generating positive alpha to begin with, hence the regulation isn't curbing positive predatory behavior.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The current simulation parameters and agent logic do not validate the core propositions of Algorithmic Predatory Equilibrium. The predators are not profitable and do not appear to induce significant volatility or information cascades. The behavioral prey exhibit consistent losses, but these are not demonstrably amplified by the presence of the current predator model. Further investigation into agent behaviors, policy learning, and market dynamics within the simulation is warranted to align with the theoretical propositions."
      ]
    }
  ]
}